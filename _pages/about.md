---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

# 👋 About Me

Hi! I'm Yang Chen, currently a Ph.D. student of COMP at [The Hong Kong Polytechnic University (PolyU, 香港理工大学)](https://www.polyu.edu.hk/en/) in Hong Kong SAR, where I'm fortunate to be supervised by [Prof. Jingcai Guo](https://jingcaiguo.github.io/). Prior to this, I received my M.Eng. degree (2024) in Information and Communication Engineering from the [University of Electronic Science and Technology of China (UESTC, 电子科技大学)](https://www.uestc.edu.cn/3974ba6dfa50d5c04a9414d3ce8bfd34.html?n=8e7z368tn51) in Chengdu, China, where I was lucky to have been advised by [Prof. Ling Wang](https://faculty.uestc.edu.cn/eewangling/zh_CN/index.htm). I also earned my B.Sc. degree (2021) in Electronic Information Science and Technology and my B.B.A. degree (2021) in Business Administration from [UESTC](https://www.uestc.edu.cn/3974ba6dfa50d5c04a9414d3ce8bfd34.html?n=8e7z368tn51).

<div class="research-with-image">
  <div class="research-image">
    <img src="images/icon_human.png" alt="Research Image">
  </div>
  <div class="research-content">
    <strong>🔬 Research Interests:</strong> My research focuses on <span class="highlight-text">data-efficient human-centric behavior analysis and modeling</span>, including but not limited to <span class="highlight-text sub-category">wireless pose sensing</span>, <span class="highlight-text sub-category">human action understanding</span>, <span class="highlight-text sub-category">motion representation learning</span>, and their <span class="highlight-text sub-category">applications in healthcare</span>. To date, I have been the core contributor to several projects closely aligned with my research interests: <br>
    
    - <span class="highlight-text sub-category">wireless pose sensing</span>: 
    <a href="https://arxiv.org/abs/2501.09411">arXiv25</a> <br>
    
    - <span class="highlight-text sub-category">human action understanding</span>: 
    <a href="https://arxiv.org/abs/2411.11288">CVPR25</a>, 
    <a href="https://dl.acm.org/doi/10.1145/3664647.3681196">MM24</a>, 
    <a href="https://ieeexplore.ieee.org/document/10742343">TCSVT24</a>, 
    <a href="https://www.sciencedirect.com/science/article/pii/S1047320323002079">JVCIR23</a> <br>
    
    - <span class="highlight-text sub-category">motion representation learning</span>: 
    <a href="https://www.sciencedirect.com/science/article/abs/pii/S0950705125007063">KBS25</a>, 
    <a href="https://ieeexplore.ieee.org/abstract/document/10812782">TMM24</a> <br>
    
    - <span class="highlight-text sub-category">applications in healthcare</span>: 
    <a href="https://ieeexplore.ieee.org/document/10530287">TNSRE24</a>, 
    <a href="https://ieeexplore.ieee.org/document/10340923">EMBC23</a>, 
    <a href="https://ieeexplore.ieee.org/abstract/document/10385735">BIBM23</a>, 
    <a href="https://www.sciencedirect.com/science/article/pii/S0952197623014781">EAAI23</a> <br>
  </div>
</div>

<span style="color: #dc3545; font-weight: 500;">Please feel free to contact me by email ([cs-yang.chen@connect.polyu.hk]()) if you are interested in discussing with me. Thanks a lot!</span>



# 🔥 News

<div class="news-container-custom">
  <ul class="news-list-custom">
    <li><em>2025.04</em>: &nbsp;🎉🎉 <a href="">HGRL</a> is accepted by <a href="https://2025.ijcai.org/">IJCAI 2025</a>!</li>
    <li><em>2025.04</em>: &nbsp;🎉🎉 <a href="https://www.sciencedirect.com/science/article/abs/pii/S0950705125007063">MLS3L</a> is accepted by <a href="https://www.sciencedirect.com/journal/knowledge-based-systems">Knowledge-Based Systems (KBS)</a>!</li>
    <li><em>2025.02</em>: &nbsp;🎉🎉 <a href="">Neuron</a> is accepted by <a href="https://cvpr.thecvf.com/">CVPR 2025</a>!</li>
    <li><em>2024.10</em>: &nbsp;🎉🎉 <a href="https://ieeexplore.ieee.org/document/10742343">SLMM</a> is accepted by <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=76">IEEE Transactions on Circuits and Systems for Video Technology (TCSVT)</a>!</li>
    <li><em>2024.09</em>: &nbsp;🎉🎉 <a href="https://ieeexplore.ieee.org/abstract/document/10812782">C2VL</a> is accepted by <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6046">IEEE Transactions on Multimedia (TMM)</a>!</li>
    <li><em>2024.07</em>: &nbsp;🎉🎉 <a href="https://dl.acm.org/doi/10.1145/3664647.3681196">STAR</a> is accepted by <a href="https://2024.acmmm.org/">ACM MM 2024</a>!</li>
    <li><em>2024.05</em>: &nbsp;🎉🎉 <a href="https://ieeexplore.ieee.org/document/10530287">EGC</a> is accepted by <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=7333">IEEE Transactions on Neural Systems and Rehabilitation Engineering (TNSRE)</a>!</li>
    <li><em>2023.12</em>: &nbsp;🎉🎉 I am admitted to the Ph.D. program at The Hong Kong Polytechnic University (PolyU) under the supervision of <a href="https://jingcaiguo.github.io/">Prof. Jingcai Guo</a>.</li>
    <li><em>2023.10</em>: &nbsp;🎉🎉 <a href="https://ieeexplore.ieee.org/abstract/document/10385735">PLFormer</a> is accepted by <a href="https://bidma.cpsc.ucalgary.ca/IEEE-BIBM-2023/">BIBM 2023</a>!</li>
    <li><em>2023.10</em>: &nbsp;🎉🎉 <a href="https://www.sciencedirect.com/science/article/pii/S1047320323002079">MGL</a> is accepted by <a href="https://www.sciencedirect.com/journal/journal-of-visual-communication-and-image-representation">Journal of Visual Communication and Image Representation (JVCIR)</a>!</li>
    <li><em>2023.10</em>: &nbsp;🎉🎉 <a href="https://www.sciencedirect.com/science/article/pii/S0952197623014781">ST-Feature</a> is accepted by <a href="https://www.sciencedirect.com/journal/engineering-applications-of-artificial-intelligence">Engineering Applications of Artificial Intelligence (EAAI)</a>!</li>
    <li><em>2023.04</em>: &nbsp;🎉🎉 <a href="https://ieeexplore.ieee.org/document/10340923">STformer</a> is accepted by <a href="https://embc.embs.org/2023/">EMBC 2023</a>!</li>
  </ul>
</div>

<div style="margin-top: 1.5em;"></div>
# 📖 Educations
<div style="margin-top: -1.5em;"></div>
<div class="education-item">
  <div class="education-logo">
    <img src="/images/logo/polyu_main.png" alt="PolyU Logo" style="width: 200px; height: 120px;">
  </div>
  <div class="education-content">
    <strong>2024.09 - Now, The Hong Kong Polytechnic University (PolyU), Hong Kong</strong><br>
    <strong>Ph.D.</strong> in Computing @ <strong><a href="https://lumen-lab-polyu.github.io/">Lumen Lab</a></strong><br>
    <strong><em>Supervisor: <a href="https://jingcaiguo.github.io/">Prof. Jingcai Guo</a></em></strong>
  </div>
</div>

<div class="education-item">
  <div class="education-logo">
    <img src="/images/logo/uestc_main.png" alt="UESTC Logo" style="width: 200px; height: 120px;">
  </div>
  <div class="education-content">
    <strong>2021.09 - 2024.06, University of Electronic Science and Technology of China (UESTC), China</strong><br>
    <strong>M.Eng.</strong> in Information and Communication Engineering @ <strong><a href="http://uestcrobot.net/">UESTC-Robot Lab</a></strong><br>
    <strong><em>Supervisor: <a href="https://faculty.uestc.edu.cn/eewangling/zh_CN/index.htm">Prof. Ling Wang</a></em></strong>
  </div>
</div>

<div class="education-item">
  <div class="education-logo">
    <img src="/images/logo/uestc_main.png" alt="UESTC Logo" style="width: 200px; height: 120px;">
  </div>
  <div class="education-content">
    <strong>2018.09 - 2021.06, University of Electronic Science and Technology of China (UESTC), China</strong><br>
    <strong>B.B.A.</strong> in Business Administration
  </div>
</div>

<div class="education-item">
  <div class="education-logo">
    <img src="/images/logo/uestc_main.png" alt="UESTC Logo" style="width: 200px; height: 120px;">
  </div>
  <div class="education-content">
    <strong>2017.09 - 2021.06, University of Electronic Science and Technology of China (UESTC), China</strong><br>
    <strong>B.Sc.</strong> in Electronic Information Science and Technology
  </div>
</div>
<div style="margin-top: -3.5em;"></div>



# 📝 Publications 

## 📋 A. Preprints

<div class="publication-item">
  <div class="publication-image" style="width: 200px; height: 80px;">
    <div>
      <div class="badge">arXiv 2025</div>
      <img src="/images/papers/chen_2025_arxiv.png" alt="arXiv 2025">
    </div>
  </div>
  <div class="publication-content">
    <span class="title-text">Towards Robust and Realistic Human Pose Estimation via WiFi Signals</span>, <br />
    <span style="font-weight: 700; font-size: 16px; text-decoration: underline;">Y. Chen</span>, J. Guo*, S. Guo, J. Zhou, D. Tao,<br>
    <em>arXiv</em>, 2025.
    <div class="publication-links">
      <a href="https://arxiv.org/abs/2501.09411" class="publication-link-tag paper">Paper</a>
      <a href="https://github.com/cseeyangchen/DT-Pose" class="publication-link-tag github">Code</a>
      <img src="https://img.shields.io/github/stars/cseeyangchen/DT-Pose?style=social" alt="GitHub stars" class="github-stars">
      <img src="https://img.shields.io/github/forks/cseeyangchen/DT-Pose?style=social" alt="GitHub forks" class="github-forks">
    </div>
  </div>
</div>

<div style="margin-top: 2em;"></div>




## 🎤 B. Conferences

<div class="publication-item">
  <div class="publication-image" style="width: 200px; height: 80px;">
    <div>
      <div class="badge">CVPR 2025</div>
      <img src="/images/papers/chen_2025_cvpr.png" alt="CVPR 2025">
    </div>
  </div>
  <div class="publication-content">
    <span class="title-text">Neuron: Learning Context-Aware Evolving Representations for Zero-Shot Skeleton Action Recognition</span>, <br />
    <span style="font-weight: 700; font-size: 16px; text-decoration: underline;">Y. Chen</span>, J. Guo*, S. Guo, D. Tao,<br>
    <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition</em> (<span class="venue-text">CVPR</span>, <span class="rank-text">CCF-A</span>), 2025.
    <div class="publication-links">
      <a href="https://openaccess.thecvf.com/content/CVPR2025/html/Chen_Neuron_Learning_Context-Aware_Evolving_Representations_for_Zero-Shot_Skeleton_Action_Recognition_CVPR_2025_paper.html" class="publication-link-tag paper">Paper</a>
      <a href="https://github.com/cseeyangchen/Neuron" class="publication-link-tag github">Code</a>
      <img src="https://img.shields.io/github/stars/cseeyangchen/Neuron?style=social" alt="GitHub stars" class="github-stars">
    </div>
  </div>
</div>

<div class="publication-item">
  <div class="publication-image" style="width: 200px; height: 85px;">
    <div>
      <div class="badge">IJCAI 2025</div>
      <img src="/images/papers/rao_2025_ijcai.png" alt="IJCAI 2025">
    </div>
  </div>
  <div class="publication-content">
    <span class="title-text">Exploring Transferable Homogeneous Groups for Compositional Zero-Shot Learning</span>, <br />
    Z. Rao, J. Guo*, M. Li, <span style="font-weight: 700; font-size: 16px; text-decoration: underline;">Y. Chen</span>, M. Wang, <br>
    <em>International Joint Conference on Artificial Intelligence</em> (<span class="venue-text">IJCAI</span>, <span class="rank-text">CCF-A</span>), 2025.
    <div class="publication-links">
      <a href="https://arxiv.org/abs/2501.10695" class="publication-link-tag paper">Paper</a>
    </div>
  </div>
</div>

<div class="publication-item">
  <div class="publication-image" style="width: 200px; height: 80px;">
    <div>
      <div class="badge">ACM MM 2024</div>
      <img src="/images/papers/chen_2024_mm.png" alt="ACM MM 2024">
    </div>
  </div>
  <div class="publication-content">
    <span class="title-text">Fine-Grained Side Information Guided Dual-Prompts for Zero-Shot Skeleton Action Recognition</span>, <br />
    <span style="font-weight: 700; font-size: 16px; text-decoration: underline;">Y. Chen</span>, J. Guo*, T. He, X. Lu, L. Wang, <br>
    <em>ACM International Conference on Multimedia</em> (<span class="venue-text">ACM MM</span>, <span class="rank-text">CCF-A</span>), 2024.
    <div class="publication-links">
      <a href="https://dl.acm.org/doi/10.1145/3664647.3681196" class="publication-link-tag paper">Paper</a>
      <a href="https://github.com/cseeyangchen/STAR" class="publication-link-tag github">Code</a>
      <img src="https://img.shields.io/github/stars/cseeyangchen/STAR?style=social" alt="GitHub stars" class="github-stars">
    </div>
  </div>
</div>



<div class="publication-item">
  <div class="publication-image" style="width: 200px; height: 65px;">
    <div>
      <div class="badge">BIBM 2023</div>
      <img src="/images/papers/chen_2023_bibm.png" alt="BIBM 2023">
    </div>
  </div>
  <div class="publication-content">
    <span class="title-text">PLFormer: Prompt Learning for Early Warning of Unplanned Extubation in ICU</span>, <br />
    <span style="font-weight: 700; font-size: 16px; text-decoration: underline;">Y. Chen</span>, T. He, X. Gao, H. Cheng, L. Wang*, <br>
    <em>IEEE International Conference on Bioinformatics and Biomedicine</em> (<span class="venue-text">BIBM</span>, <span class="rank-text">CCF-B</span>), 2023.
    <div class="publication-links">
      <a href="https://ieeexplore.ieee.org/abstract/document/10385735" class="publication-link-tag paper">Paper</a>
    </div>
  </div>
</div>

<div class="publication-item">
  <div class="publication-image" style="width: 200px; height: 45px;">
    <div>
      <div class="badge">EMBC 2023</div>
      <img src="/images/papers/chen_2023_embc.png" alt="EMBC 2023">
    </div>
  </div>
  <div class="publication-content">
    <span class="title-text">STformer: Spatial-Temporal Transformer for Early Warning of Unplanned Extubation in ICU</span>, <br />
    <span style="font-weight: 700; font-size: 16px; text-decoration: underline;">Y. Chen</span>, S. Yang, Y. Wang, G. Wang, H. Cheng, L. Wang*, <br>
    <em>Annual International Conference of the IEEE Engineering in Medicine and Biology Society</em> (<span class="venue-text">EMBC</span>), 2023.
    <div class="publication-links">
      <a href="https://ieeexplore.ieee.org/document/10340923" class="publication-link-tag paper">Paper</a>
    </div>
  </div>
</div>

<div style="margin-top: 2em;"></div>

## 📘 C. Journals

<div class="publication-item">
  <div class="publication-image" style="width: 200px; height: 80px;">
    <div>
      <div class="badge">KBS 2025</div>
      <img src="/images/papers/he_2025_kbs.png" alt="KBS 2025">
    </div>
  </div>
  <div class="publication-content">
    <span class="title-text">Multi-Level Skeleton Self-Supervised Learning: Enhancing 3D action representation learning with Large Multimodal Models</span>, <br />
     T. He, <span style="font-weight: 700; font-size: 16px; text-decoration: underline;">Y. Chen</span>, X. Gao, L. Wang, R. Huang, H. Cheng* <br>
    <em>Knowledge-Based Systems</em> (<span class="venue-text">KBS</span>, <span class="rank-text">CCF-C</span>, <span class="rank-text">JCR-Q1</span>, <span class="rank-text">IF=7.6</span>), 2025.
    <div class="publication-links">
      <a href="https://www.sciencedirect.com/science/article/abs/pii/S0950705125007063" class="publication-link-tag paper">Paper</a>
    </div>
  </div>
</div>

<div class="publication-item">
  <div class="publication-image" style="width: 200px; height: 200px;">
    <div>
      <div class="badge">TMM 2024</div>
      <img src="/images/papers/chen_2024_tmm.png" alt="TMM 2024">
    </div>
  </div>
  <div class="publication-content">
    <span class="title-text">Vision-Language Meets the Skeleton: Progressively Distillation with Cross-Modal Knowledge for 3D Action Representation Learning</span>, <br />
    <span style="font-weight: 700; font-size: 16px; text-decoration: underline;">Y. Chen</span>, T. He, J. Fu, L. Wang*, J. Guo, T. Hu, H. Cheng <br>
    <em>IEEE Transactions on Multimedia</em> (<span class="venue-text">TMM</span>, <span class="rank-text">CCF-B</span>, <span class="rank-text">JCR-Q1</span>, <span class="rank-text">IF=9.7</span>), 2024.
    <div class="publication-links">
      <a href="https://ieeexplore.ieee.org/abstract/document/10812782" class="publication-link-tag paper">Paper</a>
      <a href="https://github.com/cseeyangchen/C2VL" class="publication-link-tag github">Code</a>
    </div>
  </div>
</div>

<div class="publication-item">
  <div class="publication-image" style="width: 200px; height: 95px;">
    <div>
      <div class="badge">TCSVT 2024</div>
      <img src="/images/papers/he_2024_tcsvt.png" alt="TCSVT 2024">
    </div>
  </div>
  <div class="publication-content">
    <span class="title-text">Enhancing Skeleton-Based Action Recognition with Language Descriptions from Pre-trained Large Multimodal Models</span>, <br />
    T. He, <span style="font-weight: 700; font-size: 16px; text-decoration: underline;">Y. Chen</span>, X. Gao, L. Wang, T. Hu, H. Cheng* <br>
    <em>IEEE Transactions on Circuits and Systems for Video Technology</em> (<span class="venue-text">TCSVT</span>, <span class="rank-text">CCF-B</span>, <span class="rank-text">JCR-Q1</span>, <span class="rank-text">IF=11.1</span>), 2024.
    <div class="publication-links">
      <a href="https://ieeexplore.ieee.org/document/10742343" class="publication-link-tag paper">Paper</a>
    </div>
  </div>
</div>

<div class="publication-item">
  <div class="publication-image" style="width: 200px; height: 135px;">
    <div>
      <div class="badge">TNSRE 2024</div>
      <img src="/images/papers/he_2024_tnsre.png" alt="TNSRE 2024">
    </div>
  </div>
  <div class="publication-content">
    <span class="title-text">An Expert-Knowledge-based Graph Convolutional Network for Skeleton-based Physical Rehabilitation Exercises Assessment</span>, <br />
    T. He, <span style="font-weight: 700; font-size: 16px; text-decoration: underline;">Y. Chen</span>, L. Wang, H. Cheng*, <br/>
    <em>IEEE Transactions on Neural Systems and Rehabilitation Engineering</em> (<span class="venue-text">TNSRE</span>, <span class="rank-text">JCR-Q1</span>, <span class="rank-text">IF=5.2</span>), 2024.
    <div class="publication-links">
      <a href="https://ieeexplore.ieee.org/document/10530287" class="publication-link-tag paper">Paper</a>
    </div>
  </div>
</div>

<div class="publication-item">
  <div class="publication-image" style="width: 200px; height: 105px;">
    <div>
      <div class="badge">EAAI 2023</div>
      <img src="/images/papers/chen_2023_eaai.png" alt="EAAI 2023">
    </div>
  </div>
  <div class="publication-content">
    <span class="title-text">Spatio-Temporal Features for Fast Early Warning of Unplanned Self-Extubation in ICU</span>, <br />
    <span style="font-weight: 700; font-size: 16px; text-decoration: underline;">Y. Chen</span>, L. Wang*, G. Wang, S. Yang, Y. Wang, M. Xiang, X. Zhang, H. Chen, D. Hu, H. Cheng, <br />
    <em>Engineering Applications of Artificial Intelligence</em> (<span class="venue-text">EAAI</span>, <span class="rank-text">CCF-C</span>, <span class="rank-text">JCR-Q1</span>, <span class="rank-text">IF=8.0</span>), 2023.
    <div class="publication-links">
      <a href="https://www.sciencedirect.com/science/article/pii/S0952197623014781" class="publication-link-tag paper">Paper</a>
    </div>
  </div>
</div>


<div class="publication-item">
  <div class="publication-image" style="width: 200px; height: 80px;">
    <div>
      <div class="badge">JVCIR 2023</div>
      <img src="/images/papers/chen_2023_jvcir.png" alt="JVCIR 2023">
    </div>
  </div>
  <div class="publication-content">
    <span class="title-text">Multi-view Graph Convolution Network for the Recognition of Human Action with Spatial and Temporal Occlusion Problems</span>, <br />
    <span style="font-weight: 700; font-size: 16px; text-decoration: underline;">Y. Chen</span>, L. Wang*, D. Hu, H. Cheng, <br />
    <em>Journal of Visual Communication and Image Representation</em> (<span class="venue-text">JVCIR</span>, <span class="rank-text">CCF-C</span>, <span class="rank-text">JCR-Q2</span>, <span class="rank-text">IF=3.1</span>), 2023.
    <div class="publication-links">
      <a href="https://www.sciencedirect.com/science/article/pii/S1047320323002079" class="publication-link-tag paper">Paper</a>
      <a href="https://github.com/cseeyangchen/MGL" class="publication-link-tag github">Code</a>
    </div>
  </div>
</div>

<div style="margin-top: 2em;"></div>

## 💡 D. Patents

- <span class="title-text"> A Method for Optimizing Dietary Energy Intake in Cancer Patients</span>, <br />
T. Zhang, Y. Liu, <span style="font-weight: 700; font-size: 16px; text-decoration: underline;">Y. Chen</span>, L. Wang, G. Wang, J. Qiu, Y. Ren, H. Zhou, Y. Gao, X. Zhang, M. Tang, K. Li, X. Meng, M. Liu, L. Wang, <br />
Public Number: CN 116665843 B, Application Date: 2023-07-28, Public Date: 2023-10-13

- <span class="title-text">  A Approach for Early Warning of Self-extubation Behavior of ICU Patients Based on RGB Video Monitoring </span>, <br />
<span style="font-weight: 700; font-size: 16px; text-decoration: underline;">Y. Chen</span>, L. Wang, Y. Wang, S. Yang, G. Wang, <br />
Public Number: CN 115565245 A, Application Date: 2022-10-10, Public Date: 2023-01-03


# 🎖 Honors and Awards
- Academic Scholarship of UESTC, 2018.10 - 2024.10
- IEEEXtreme 16.0 Programming Winner (Top 13%), 2022.10
- The Third Prize in the Huawei Software Elite Challenge, 2022.04
- Meritorious Winner in COMAP'S Mathematical Contest in Modeling (Top 6%), 2020.05



# 💻 Academic Services
- 📚 Journal Reviewer: TIP, TCSVT, JBHI, NN, INFFUS, BSPC, OJ-CS
- 👥 Conference Reviewer: NeurIPS, ICLR, ICML, ACM-MM, AAAI, IJCAI, MICCAI



<div style="margin-top: -1em;"></div>
<div class="visitor-map-section">
  <div class="clustrmaps-widget">
    <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=c9c9c9&w=a&t=tt&d=DQMgyx3X0ISPpoe8T9jJELKbWcQy4zofQD1Fm9T8Ve8&co=ffffff'></script>
  </div>
</div>